{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Abstract","text":"<p>Crowd-Vision is a web app simplifying the management of a structure through a  digital twin, by monitoring (and showing) in real time the people inside it, thanks  to several sensors.</p> <p>The goal is to allow a better management and security of movements and study through an interactive map and tools.</p>"},{"location":"#main-features","title":"Main features","text":"<ul> <li>Real time visualization: High-frequency updates via WebSocket technology to monitor crowd density.</li> <li>Push Notifications: Server-initiated alerts for security issues, overcrowded areas, or temperature anomalies (Web Push &amp; In-App).</li> <li>Digital Twin Management:<ul> <li>Full 3D visualization of buildings and rooms.</li> <li>Multi-domain support for managing different environments.</li> <li>Edit room properties (capacity, layout) directly from the dashboard.</li> </ul> </li> <li>Interactive Tools:<ul> <li>Search rooms by name or attributes.</li> <li>Selection by 3D object interaction.</li> <li>Building controls and visual feedback.</li> </ul> </li> </ul>"},{"location":"#technical-aspects","title":"Technical aspects","text":"<p>Built on top of MEVN stack (MongoDB, Express.js, Vue.js, Node.js) with a microservices architecture.</p>"},{"location":"architecture/","title":"Architecture","text":"<p>Crowd Vision is a scalable, digital-twin solution designed to monitor and visualize crowd density within building structures in real-time. The system employs an event-driven architecture to handle high-frequency data streams from IoT sensors, visualizing them on a 3D web dashboard.</p>"},{"location":"architecture/#1-high-level-architecture","title":"1. High-level architecture","text":"<p>The system follows a Client-Server architecture, with the server composed by multiple microservices. A Caddy reverse proxy acts as the single entry point (Gateway), managing the internal network and routing requests to specific autonomous services.</p> <p>The backend is divided into four core domain services:</p> <ul> <li>Authentication Service: Manages user identity and access control.</li> <li>Digital Twin Service: Manages the state, configuration, and hierarchy of building digital twins.</li> <li>Socket Service: Handles real-time bi-directional communication (WebSockets) for sensor data streaming.</li> <li>Notification Service: Manages subscription and delivery of push notifications (Web Push and In-App).</li> <li>LLM Service: Provides AI capabilities using Large Language Models (LLMs) like DeepSeek and Gemini. It handles prompt engineering, context retrieval, and reasoning tasks.</li> </ul> <pre><code>graph TD\n    User[User Dashboard] --&gt;|HTTPS| Proxy[Caddy Proxy Gateway]\n    Sensors[IoT Sensor Network] --&gt;|HTTPS| Proxy\n\n    subgraph \"Internal Network (Microservices)\"\n        direction TB\n        Proxy --&gt;|/auth/*| Auth[Authentication Service]\n        Proxy --&gt;|/digital-twin/*| Twins[Digital Twin Service]\n        Proxy --&gt;|/sensors/*| Data[Data Processing Service]\n        Proxy --&gt;|/socket.io/*| Socket[Socket Service]\n        Proxy --&gt;|/notification/*| Notify[Notification Service]\n\n        Socket &lt;--&gt;|Pub/Sub| Redis[Redis Broker]\n        Notify &lt;--&gt;|Read| Redis\n\n        Auth &lt;--&gt;|Read/Write| AuthDB[(Auth MongoDB)]\n        Twins &lt;--&gt;|Read/Write| TwinsDB[(Twins MongoDB)]\n        Data &lt;--&gt;|Read/Write| DataDB[(Sensor Data MongoDB)]\n\n        Proxy --&gt;|/ai/*| LLM[LLM Service]\n        LLM &lt;--&gt;|Read| Redis\n    end</code></pre>"},{"location":"architecture/#2-infrastructure-deployment","title":"2. Infrastructure &amp; Deployment","text":"<p>The application infrastructure is containerized, with services orchestrated via Docker Compose.</p> <ul> <li>Gateway Layer: Caddy handles SSL termination, load balancing, and routing to the internal Docker network.\u00f9</li> <li>Database Layer: We adhere to the Database-per-Service pattern. Each microservice connects to its own dedicated MongoDB instance to ensure loose coupling and independent scaling.</li> <li>Message Broker: Redis is used for inter-service communication and Pub/Sub messaging for real-time updates.</li> </ul>"},{"location":"architecture/#3-core-components-technology-stack","title":"3. Core components &amp; Technology stack","text":""},{"location":"architecture/#client-frontend","title":"Client / Frontend","text":"<ul> <li>Framework : Vue3</li> <li>Twin visualization : Three.js</li> <li>Styling : Tailwind CSS</li> <li>Build tool : Vite</li> </ul>"},{"location":"architecture/#authentication-service","title":"Authentication Service","text":"<p>Responsible for all security-related operations.</p> <ul> <li>Stack: Node.js / TypeScript.</li> <li>Responsibilities: User registration, login and validating session states.</li> <li>Data: Stores user credentials and profile information.</li> </ul>"},{"location":"architecture/#digital-twin-service","title":"Digital twin Service","text":"<p>Handles the static and dynamic configuration of the monitored environments.</p> <ul> <li>Stack: Node.js / TypeScript.</li> <li>Responsibilities: CRUD operations for buildings, rooms, and sensor placement configurations.</li> <li>Data: Stores 3D models metadata and building hierarchy.</li> </ul>"},{"location":"architecture/#data-processing-service","title":"Data processing Service","text":"<p>The high-throughput component that handles real-time streams.</p> <ul> <li>Stack: Node.js / TypeScript.</li> <li>Responsibilities: Receives raw sensor data, filters noise, aggregates readings, and prepares data for the frontend visualization.</li> <li>Data: Stores historical sensor logs and processed metrics.</li> </ul>"},{"location":"architecture/#socket-service","title":"Socket Service","text":"<p>The real-time gateway that handles WebSocket connections. - Stack: Node.js / TypeScript / Redis / Socket.io. - Responsibilities: Establishes persistent connections with clients and sensors to stream live data.</p>"},{"location":"architecture/#notification-service","title":"Notification Service","text":"<p>Manages alerts and user subscriptions. - Stack: Node.js / TypeScript / Redis. - Responsibilities: Handles VAPID key generation, push subscription management, and dispatching alerts (overcrowding, temperature) via Web Push protocol.</p>"},{"location":"data/","title":"Data model","text":"<p>How are data modeled in our application? Piece of cake! To upload a building you just need a json file which describe it!</p> <pre><code>{\n  \"id\": string,\n  \"rooms\": [\n    {\n      \"id\": string,\n      \"capacity\": number,\n      \"temperature\": number,\n      \"no_person\": number,\n      \"color\": string,\n      \"position\": {\n        \"x\": number,\n        \"y\": number,\n        \"z\": number\n      },\n      \"dimensions\": {\n        \"width\": number,\n        \"height\": number,\n        \"depth\": number\n      }\n    }\n  ],\n  \"domains\": [\n    string\n  ]\n}\n</code></pre>"},{"location":"data/#fields-description","title":"Fields Description","text":"Field Type Description id <code>string</code> Unique identifier for the building. domains <code>string[]</code> List of administrative domains the building belongs to. rooms <code>object[]</code> List of rooms contained within the building."},{"location":"data/#room-object","title":"Room Object","text":"Field Type Description id <code>string</code> Unique identifier for the room. capacity <code>number</code> Maximum number of people allowed. temperature <code>number</code> Current temperature reading. maxTemperature <code>number</code> (Optional) Threshold for temperature alerts. no_person <code>number</code> Current crowd count. color <code>string</code> (Optional) Hex code for visual representation. position <code>x, y, z</code> Coordinates of the room in 3D space. dimensions <code>w, h, d</code> Physical dimensions of the room. <p>Thus the input simplicity, is not always easy find the correct position and dimension, allowing a great user experience!</p>"},{"location":"design/","title":"Design","text":""},{"location":"design/#sensors-simulation","title":"Sensors simulation","text":"<p>This project implements a scalable architecture for simulating an IoT sensor network.</p> <p>The solution utilizes Node.js scripts integrated with Faker.js to generate stochastic, realistic environmental data.  Data transmission is handled via WebSockets (Socket.io), replacing traditional HTTP polling with an event-driven \"push\"  mechanism. The architecture employs a many-to-one multiplexing pattern, where multiple autonomous simulated clients\u2014representing distinct classrooms\u2014transmit data asynchronously to a centralized Express.js backend through a shared socket channel.</p> <p>Identification of individual sensors is managed via unique IDs embedded within the JSON payload.</p>"},{"location":"design/#data-exchange","title":"Data exchange","text":"<p>Between the Vue.js client and the Express server there would be open a websocket where processed data from the server are  pushed towards the client.  1. Sensor -&gt; Server: Simulated sensors push telemetry data (updates on people count, temperature) to the Socket Service. 2. Server -&gt; Client: The Socket Service broadcasts these updates to connected Vue.js clients subscribed to the specific room or building topics. 3. Alerts: If data thresholds are breached (e.g., temperature &gt; maxTemperature), events are published to Redis. The Notification Service consumes these events and triggers Push Notifications to relevant users.</p>"},{"location":"design/#domains","title":"Domains","text":"<p>The Domain System introduces a multi-tenant layer to <code>auth-service</code>. It decouples the \"User\" from a single entity, allowing many-to-many relationships via Memberships.</p>"},{"location":"design/#1-data-model","title":"1. Data Model","text":""},{"location":"design/#domain-schema","title":"Domain Schema","text":"<p>The <code>Domain</code> entity defines the configuration for an organization. * <code>name</code>: Unique identifier (Primary Key logic). * <code>authStrategy</code>: Determines how users access the domain.     * <code>internal</code>: Standard CrowdVision auth.     * <code>oidc</code>: OpenID Connect for external integration. * <code>ssoConfig</code>: (Encrypted) Stores <code>clientId</code>, <code>clientSecret</code>, and <code>issuerUrl</code> for SSO domains.</p> <pre><code>// Schema Reference\nexport interface IDomain {\n  name: string;\n  subdomains: string[];\n  authStrategy: \"internal\" | \"oidc\";\n  ssoConfig?: {\n    issuerUrl: string;\n    clientId: string;\n    clientSecret: string;\n  };\n}\n</code></pre>"},{"location":"design/#user-membership","title":"User Membership","text":"<p>Users are not \"in\" a domain; they have memberships. This allows a single user to be an Admin in <code>Domain A</code> and a Viewer in <code>Domain B</code>.</p> <pre><code>export interface IDomainMembership {\n  domainName: string;\n  role: \"owner\" | \"admin\" | \"viewer\";\n}\n</code></pre>"},{"location":"design/#2-authentication-workflow","title":"2. Authentication Workflow","text":""},{"location":"design/#authentication-flows","title":"Authentication Flows","text":"<p>Standard Flow (Internal) - User clicks \"Subscribe\". - Client calls <code>POST /subscribe</code>. - Backend verifies domain exists and adds a viewer membership to the user document.</p> <p>SSO Flow (OIDC) - User clicks \"Subscribe\". - Client detects <code>authStrategy === 'oidc'</code>. - Client requests a redirect URL via <code>/auth/sso/login</code>. - User authenticates with the external Identity Provider (IdP). - IdP calls back to <code>auth-service</code>, which validates the token and adds the membership.</p>"},{"location":"llm/","title":"LLM Service Architecture","text":"<p>The LLM Service is a new microservice introduced in v2.0.0 to decouple AI logic from the core application. It acts as an intelligent layer that processes natural language and generates insights based on system data.</p>"},{"location":"llm/#technology-stack","title":"\ud83c\udfd7\ufe0f Technology Stack","text":"<p>We chose a lightweight but robust stack to handle AI requests efficiently:</p> <ul> <li>Runtime: Node.js</li> <li>Framework: Fastify (Selected for low overhead and high performance)</li> <li>Orchestration: LangChain.js</li> <li>Models:<ul> <li>DeepSeek (Chat &amp; Reasoner): Used for complex logic and cost-effective queries.</li> <li>Google Gemini (Flash Lite): Used for high-speed, multimodal tasks.</li> </ul> </li> </ul>"},{"location":"llm/#why-a-separate-service","title":"\ud83e\udde0 Why a Separate Service?","text":""},{"location":"llm/#1-isolation-of-heavy-dependencies","title":"1. Isolation of Heavy Dependencies","text":"<p>AI libraries (like LangChain) and SDKs are heavy. By isolating them in a separate container, we keep the <code>auth-service</code> and <code>twin-service</code> lightweight and fast.</p>"},{"location":"llm/#2-independent-scaling","title":"2. Independent Scaling","text":"<p>AI inference is computationally expensive and latency-prone compared to simple CRUD operations. This architecture allows us to scale the <code>llm-service</code> independently (e.g., adding more replicas) without affecting the real-time performance of the <code>socket-service</code>.</p>"},{"location":"llm/#3-model-agnosticism","title":"3. Model Agnosticism","text":"<p>The service uses <code>LangChain</code> to abstract the underlying model providers. This allows us to switch between DeepSeek, Gemini, or OpenAI by simply changing environment variables, without rewriting business logic.</p>"},{"location":"llm/#api-integration","title":"\ud83d\udd0c API &amp; Integration","text":"<p>The service exposes a REST API via Fastify.</p> <ul> <li>Prefix: <code>/api</code></li> <li>Routes: Auto-loaded from the <code>routes/</code> directory.</li> </ul>"},{"location":"llm/#example-configuration-env","title":"Example Configuration (<code>.env</code>)","text":"<p>To run the service, ensure the following API keys are set in your environment:</p> <p>```bash DEEPSEEK_API_KEY=sk-... GOOGLE_API_KEY=AIza...</p>"},{"location":"requirements/","title":"Requirements","text":""},{"location":"requirements/#real-time-visualization","title":"Real time visualization","text":"<p>Real time structure twin, allowing both generic users and admin ones to consult the status of the structure. By simulating  sensors we can simulate temperature ones and movements ones too, thanks to websocket we can create a quick communication between the express server and the vue client</p>"},{"location":"requirements/#push-server-initiated-notifications","title":"Push server-initiated notifications","text":"<p>Some kind of notifications, like when a certain area temperature raise above the comfort one, or when is overcrowded</p>"},{"location":"requirements/#history-and-data-logs","title":"History and data logs","text":"<p>An aggregate view of all data with some statistics (maybe by hours or kinda), with graphs and comparison between different structures or floors</p>"},{"location":"requirements/#llm-integration","title":"LLM integration","text":"<p>Campus conversational assistant: users can ask questions in natural language such as \"where can I currently find a less crowded classroom to study?\"  or \"when is the best time to go to the canteen?\", and the LLM translates the request into a query on the digital twin and returns an understandable textual answer.</p> <p>Automatic report generation for the admin: starting from crowd statistics, the LLM synthesizes brief reports  (\"this week, peak attendance shifted from library A to library B in the evening hours\").</p> <p>\"Intelligent\" push notifications: instead of static messages, the backend calls the LLM to generate different natural texts depending on the user type and the event (\"area X is very crowded, we recommend Y as an alternative\").</p>"}]}